#
# Example slurm.conf file. Please run configurator.html
# (in doc/html) to build a configuration file customized
# for your environment.
#
#
# slurm.conf file generated by configurator.html.
#
# See the slurm.conf man page for more information.
#
ClusterName=ngc
ControlMachine=circe-login

# TODO: configure a HA Slurm clusters with our Ansible Module
#ControlAddr=
#BackupController=
#BackupAddr=

SlurmUser=slurm
SlurmctldPort=6817
SlurmdPort=6818
AuthType=auth/munge
#JobCredentialPrivateKey=
#JobCredentialPublicCertificate=
StateSaveLocation=/var/spool/slurm/ctld
SlurmdSpoolDir=/var/spool/slurm/d
SwitchType=switch/none
MpiDefault=none
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid
ProctrackType=proctrack/cgroup
PluginDir=/usr/lib/slurm
#FirstJobId=
ReturnToService=1
#MaxJobCount=
#PlugStackConfig=
#PropagatePrioProcess=
#PropagateResourceLimits=
#PropagateResourceLimitsExcept=
PropagateResourceLimitsExcept=MEMLOCK
PrologFlags=alloc

Prolog=/etc/slurm/prolog.d/*
Epilog=/etc/slurm/epilog.d/*
MailProg=/usr/bin/heirloom-mailx
#SrunProlog=
#SrunEpilog=
#TaskProlog=
#TaskEpilog=
TaskPlugin=affinity,cgroup
#TrackWCKey=no
#TreeWidth=50
#TmpFS=
#UsePAM=
#
# TIMERS
SlurmctldTimeout=300
SlurmdTimeout=300
InactiveLimit=0
MinJobAge=300
KillWait=30
Waittime=0
#
# SCHEDULING
SchedulerType=sched/backfill
SchedulerParameters=kill_invalid_depend,nohold_on_prolog_fail
#SchedulerAuth=
SelectType=select/cons_res
SelectTypeParameters=CR_Core_Memory,CR_CORE_DEFAULT_DIST_BLOCK,CR_ONE_TASK_PER_CORE
FastSchedule=1
PriorityType=priority/multifactor
PriorityDecayHalfLife=14-0
PriorityFavorSmall=YES
#PriorityUsageResetPeriod=14-0
PriorityWeightFairshare=100000
PriorityWeightAge=1000
PriorityWeightPartition=10000
PriorityWeightJobSize=1000
PriorityMaxAge=1-0
#
# LOGGING
SlurmctldDebug=3
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdDebug=3
SlurmdLogFile=/var/log/slurm/slurmd.log
JobCompType=jobcomp/none
#JobCompLoc=
#
# ACCOUNTING
JobAcctGatherType=jobacct_gather/cgroup
#JobAcctGatherFrequency=30
#
AccountingStorageEnforce=associations,limits,qos
AccountingStorageTRES=gres/gpu
DebugFlags=CPU_Bind,gres
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageHost=localhost
#AccountingStorageLoc=
AccountingStorageUser=slurm
AccountingStoragePass=/var/run/munge/munge.socket.2
#
# MANAGEMENT NODE
#
NodeName=circe-mgmt-01 CPUs=48 Sockets=2 CoresPerSocket=12 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
#
# COMPUTE NODES
NodeName=circe-n001     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n002     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n003     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n004     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n005     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n006     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n007     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n008     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n009     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n010     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n011     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n012     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n013     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n014     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n015     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n016     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n017     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n018     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n019     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n020     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n021     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n022     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n023     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n024     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n025     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n026     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n027     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n028     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n029     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n030     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n031     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n032     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n033     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n034     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n035     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN
NodeName=circe-n036     CPUs=96 Sockets=2 CoresPerSocket=24 ThreadsPerCore=2 Procs=48 RealMemory=1469490 State=UNKNOWN

# hardcoding the partitions and default memory per node
# TODO: automatically define the partitions by resource
# TODO: set DefMemPerCPU = TotalMemory / LogicalCPUs
PartitionName=batch Nodes=circe-n[001-036] Default=YES DefMemPerNode=1469490 MaxMemPerNode=1469490 State=UP  OverSubscribe=EXCLUSIVE  MaxTime=INFINITE  DefaultTime=00:30:00  AllowQos=ALL

